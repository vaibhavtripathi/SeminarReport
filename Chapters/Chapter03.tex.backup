%************************************************
\chapter{Sentiment Analysis as a Classification Problem}\label{ch:saosm}
%************************************************

The essence of sentiment analysis is to label a piece of text (or aspect) as positive, negative or neutral. In modern times, after the unprecedented level of development in the 
machine learning area, we can  easily formulate the problem as a 
classification problem and solve it with machine learning techniques. This has proved to be an extremely successful approach in the past. The most important task here is to 
come up with the right features, and classification tools will do the rest.

\vspace{8mm}

However, one of the first attempts to solve sentiment analysis as a classification problem came as early as 2002 by Turney. This was an unsupervised approach.

\section{Unsupervised Classification}

Turney identified that there are some fixed syntactic patterns that are more likely to express sentiments.
The syntactic patterns are composed based on part-of-speech (POS) tags. Turney took the phrases that conformed to these patterns as his indicators of sentiment.

The algorithm consists of three steps:

\subsection{Extracting of sentiment phrases}

\textbf{I\_PRP had\_VBD a\_DT long\_JJ day\_NN}

In this example, "long day" seems to contain a sentiment.

\vspace{8mm}

Turney handcrafted some POS tag sequences that should be extracted from the text to analyze for sentiment. The exhaustive list is given in the following table:

\begin{center}
    \begin{tabular}{| l | l | l |}
    \hline
    \textbf{First Word} & \textbf{Second Word} & \textbf{Third Word (Not Extracted)} \\ \hline
   JJ & NN or NNS & anything    \\ \hline
    RB or RBR or RBS & JJ & not NN or NNS \\ \hline
    JJ & JJ & not NN or NNS \\ \hline
    NN or NNS & JJ & not NN or NNS \\ \hline
    RB or RBR or RBS & VB, VBD, VBN or VBG & anything \\ \hline
    \end{tabular}
\end{center}

And as it should be, "long day" conforms to the first pattern, and hence must be extracted.

\subsection{Calculating sentiment score of extracted phrases}

For calculating the sentiment scores of extracted phrases, a measure of closeness (or distance) between two phrases is required. We can then find the closeness of the extracted phrase from two reference
phrases - one positive and one negative. The closer reference phrase will decide the sentiment of this new phrase.

\vspace{8mm}

A measure of distance is Pointwise Mutual Information (PMI). It is given as:
\begin{framed}
 \begin{equation*}
PMI(term_1, term_2) = log_2 \left( \frac{ Pr(term_1, term_2) }{Pr(term_1)Pr(term_2)} \right)
\end{equation*}
\end{framed}

As evident, this measure sees closeness between two phrases as the number of times they have occured together in some text.
Now, to calculate the sentiment orientation of a given phrase, we calculate its PMI with two reference phrases - excellent and poor.

\begin{framed}
 \begin{equation*}
SO(phrase) = PMI(phrase, `excellent`) - PMI(phrase, `poor`)
\end{equation*}
\end{framed}

If the phrase is closer to "excellent" than to "poor", SO(phrase) will turn out to be a positive value. In such a case, the new phrase can be labelled as positive, otherwise negative.

\subsection{Assigning label to the text}

For the given text, the average SO score over all the extracted phrases is calculated. Then, depending on the final value, we can label the entire text as positive or negative.

\vspace{8mm}

This approach seems like a naive approach. However, it has shown classification accuracies on reviews from various domains ranging from 84\% for automobile reviews to 66\% for movie reviews.
A little advancement over this approach uses sentiment lexicons to determine the SO score of the phrases. Rest of the procedure is exactly the same. Sentiment lexicons are precomputed
dictionaries containing the sentiment scores of common phrases.

\section{Supervised Classification}

Supervised machine learning techniques have been used for solving problems in NLP for a very long time now. They find application in almost all areas in Natural Language Processing, 
for example, topic-based text categorization. Thus, it was proposed that machine learning techniques should be useful in sentiment analysis too, which was found to be true.

\vspace{8mm}

The following technique basically models sentiment analysis as a topic-based categorization problem where positive and negative are two topics, and we have to find which topic
a given text belongs to. For applying machine learning strategies, Then, each document d is represented by the document vector $d := (n_1(d), n_2(d), . . . , n_m(d))$. Here, $n_i(d)$
denotes the frequency of occurence of feature $f_i$ in document d. Note that we have considered n different features.

\subsection{Naive Bayes}

The probabilistic approach to the problem goes like this:

\vspace{8mm}

Let $c*$ denote the actual class (positive or negative) of the given text document $d$. Then, we formulate the following argmax expression:

\begin{framed}
 \begin{equation*}
c* = arg max_c P(c | d)
\end{equation*}
\end{framed}

By Bayes rule:

\begin{framed}
 \begin{equation*}
c* = argmax_c \frac{P(c) P(d | c)}{P(d)}
\end{equation*}
\end{framed}

Since P(d) is common for all c, it plays no role in deciding the resulting c.

\begin{framed}
 \begin{equation*}
c* = argmax_c P(c) P(d | c)
\end{equation*}
\end{framed}

Now, $P(d | c)$ can be determined easily by breaking it down into the feature representation. 

\begin{framed}
 \begin{equation*}
P(c | d) = \frac{P(c) \prod_{i=1}^{m} P(f_i | c)^{n_{i(d)}}}{P(d)}
\end{equation*}
\end{framed}

With unigram and POS tag features, Naive Bayes have reported upto 81.5 accuracy.

\subsection{Maximum Entropy}


The argmax expression is the same for maximum entropy classification but the probability $P(c | d)$ is given differently:

 \begin{framed}
 \begin{equation*}
P (c | d) = \frac{1}{Z(d)} exp \sum_{i}^{m} \lambda_{i,c} F_{i,c} (d, c)
\end{equation*}
\end{framed}

Note that $F_{i,c}(d,c')$ fires if and only if $c'=c$ and $n_i(d)>0$. That is, when a particular feature $f_i$ is known to occur in the document and the documentâ€™s sentiment is hypothesized
to be c (negative or postive). Importantly, unlike Naive Bayes, MaxEnt makes no assumptions about the relationships between features, and so might potentially perform better when conditional independence assump-
tions are not met.

\vspace{8mm}

The parameter values $\lambda$ are set so as to maximize the entropy of the distribution subject to the constraint that the expected values of the feature/class functions
with respect to the model are equal to their expected values with respect to the training data - that is the model should make the fewest assumptions about the data while being
consistent with it.

\subsection{Support Vector Machines}


SVM has proved to be the most successful in other NLP applications already. It is also the most widely used classification algorithm used today. SVMs are large-margin classifiers. 
In the binary-classification case, the basic idea behind the training procedure is to find a hyperplane, that not only separates the document vectors in one class
from those in the other, but for which the separation, or margin, is as large as possible.

 \begin{framed}
 \begin{equation*}
w = \sum_{j} \alpha_j c_j d_j, \alpha_j > 0
\end{equation*}
\end{framed}

The required hyperplane is given by vector $w$. Support vectors are those documents $d$ for which the $\alpha$ value turns out to be greater than zero.

\vspace{8mm}


These were the broad classification strategies that have proved very useful in sentiment analysis. Although the performance is nowhere near to perfect, it is still remarkable.
Moreover, there are deep learning based techniques too, which have proved to be even more useful for sentiment analysis, achieving accuracy as high as 84\%.

\section{Information Retrieval based Sentiment Analysis}

This is also an unsupervised approach like Turney's. Remember we discussed that sentiment words can be ambiguous, meaning differently in different contexts.
Determining contextual polarity of sentiment words is thus a challenging task. Here, we have discouraged the use of hand-crafted rules or sentiment lexicons.
Rather, the problem is formulated as an information retrieval problem and solved using information retrieval approach.

\vspace{8mm}

Consider this:

\vspace{8mm}

\textbf{Pizza is cold.} \hspace{10mm}
\textbf{Beer is cold.}

\vspace{8mm}

As we can see, the same word is used for two different sentiments and there are no other differences in the two sentences to tell the sentiments apart for the system.
The solution is very simple and obvious. It goes like this:

\vspace{8mm}

For a sentiment word $a$, two vectors of different contexts need to be created, one each for the positive and the negative set.
When word $a$ appears during test phase, the approach treats the current word context vector as query and the prepared context vectors as documents.
The polarity of $a$ is decided by the document which is retrieved after providing the input query.

\vspace{8mm}

The context feature vector is created as follows:

\vspace{8mm}

First of all, just like Turney's unsupervised classification, the relevant phrases have to be extracted. For this, we concentrate on nouns. The first task is to locate all 
nouns that appear as governing words for a dependency relation. Here, a filter is applied to select only the nouns that interest us i.e. only the nouns belonging to that
particular domain. The algorithm can be listed in the following steps:

\begin{enumerate}
\setlength{\itemsep}{15pt}
 \item For each governing word (noun), dependency triple of the form $DepRel(n,a)$ is to be extracted. Dependency relation can be an adjectival modifier (amod), nominal subject (nsubj)
or relative clause modifier (rcmod). For example, \textbf{nsubj(pizza,hot)}
 \item For each adjective instance $a$ extracted in this way, all triples where $a$ appears as dependent must be extracted. For each adjective occurrence, the following information is recorded:

\begin{enumerate}
 \item negation (1, if adjective is negated; 0, if adjective is not negated)
 \item dependency relation of adjective with its governing noun (amod, nsubj or rcmod)
 \item adjective lemma
\end{enumerate}
 
These three pieces of information form a adjective pattern (AdjP), e.g., \textbf{0; amod; better}. A context feature vector is built for each of these patterns.
The reason why building vectors is essential as opposed to just adjective lemmas is that, firstly, we want to differentiate between the negated and non-negated
instances, and, secondly, we want to capture the syntactic usages of the adjective. This is important because adjectives occurring in a post-modifier position tend to be used more in 
evaluative manner, and are thus, more important for our analysis compared to those used in premodifier
position (\textbf{drink is cold} vs \textbf{cold drink}).

\item For each adjective instance thus created, represented as \textbf{negation; dependency relation; lemma}, all dependency relations that contain it must be extracted. Each of
them is transformed into a context feature f of the form: \textbf{lemma; Part Of Speech (POS); dependency relation}. For instance, if adjective \textbf{cold} occurs in dependency
triple nsubj(drink, cold), the following feature is created - \textbf{drink; NN; nsubj}. For each feature, its frequency of co-occurrence with the adjective pattern is recorded.

\item After we have generated vectors for all $AdjP$ patterns extracted from the positive
set and the negative set separately, we can now determine the polarity of a specific adjective occurence. In this approach, the sentence (containing the adjective) only is used to
generate the vector in a similar manner as before. This vector is called $EVal_{AdjP}$.
The pairwise similarity of $Eval_{AdjP}$ with $posV_{AdjP}$ (vector constructed from positive examples)
and $Eval_{AdjP}$ with $negV_{AdjP}$ (vector constructed from negative examples) is computed. If similarity with $posV_{AdjP}$ is higher, it is categorized
as positive, and as negative if similarity with $negV_{AdjP}$ is higher.

\end{enumerate}

\vspace{8mm}

Computing similarity is where the role of information retrieval comes in. The vector $Eval_{VAdjP}$ of a specific adjective occurrence AdjP, whose
polarity we want to determine, is treated as the query, while the two vectors $posV_{AdjP}$ and $neg_{VAdjP}$ created from the positive and negative training sets respectively,
are treated as documents. For the purpose of computing similarity we use Query Adjusted Combined Weight (QACW) document retrieval function:
\vspace{12mm}


\begin{framed}
 \begin{equation*}
Sim(EvalV_{AdjP}, V_{AdjP}) = \sum_{f=1}{F} \frac{TF(k_1+1)}{K + TF} \times QTF \times IDF_f
\end{equation*}
\end{framed}

where,

\vspace{8mm}

F : the number of features that $EvalV_{AdjP}$ and $V_{AdjP}$ have in common \\
TF : frequency of feature f in $V_{AdjP}$ \\
QTF : frequency of feature f in $EvalV_{AdjP}$  \\
K : $k_1 \times (1 - b) + b \times \frac{DL}{AVDL}$ \\
k1 : feature frequency normalization factor\\
b : $V_{AdjP}$ length normalization factor\\
DL : number of features in VAdjP\\
AVDL : average number of features in the vectors V for all AdjP patterns in the training set (positive or negative)

\vspace{8mm}

Frequency) of the feature f is calculated as $IDF_f = log(\frac{N}{n_f})$, where, $n_f$: number of
vectors V in the training set (positive or negative) containing feature f; N: total number
of vectors V in the training set.

\vspace{8mm}

A polarity score of AdjP is calculated for both
positive and negative sets:

\begin{framed}
 \begin{equation*}
Polarity Score = \alpha \times Sim(EvalV_{AdjP}, V_{AdjP}) + (1 - \alpha) \times P(AdjP)
\end{equation*}
\end{framed}

where P(AdjP) is calculated as number of occurrences of AdjP in the set (positive
or negative) divided by the total number of occurrences of all AdjP patterns in this set. If Polarity Score is higher for the positive set, the polarity is positive,
and if lower, it is negative.
 





